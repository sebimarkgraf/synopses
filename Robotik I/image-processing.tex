
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "robotik"
%%% End:

\section{Bildverarbeitung}%
\label{bv:sec:bildverarbeitung}
Durch Sehen dem Roboter die Wahrnehmung der Umwelt wahrnehmen\\
Bilderfassung: Hardware\\
Bildverarbeitung: überwiegend Software

\subsection{Bildrepräsentation}%
\label{bv:sub:bildrepraesentation}
Bildkoordinaten
\begin{itemize}
\item \(u\) horizontal
\item \(v\) vertikal
\item Ursprung oben links
\item Einheit: Pixel
\end{itemize}

Monochrombild: \(\mathit{Img}: [0 \cdots n - 1] \times [0 \cdots m-1] \rightarrow [0\dots q]\)\\
Farbbild: \(\mathit{Img}(u,v) = (r,g,b)^T \in \realnumbers^3\)

\subsection{Kameramodell}%
\label{bv:sub:kameramodell}
Einfachstes Modell: Lochkamera\\

\textbf{Koordinatensysteme}
\begin{itemize}
\item Hauptachse: Gerade durch das Projektionszentrum, rechtwinklig zur Bildebene
\item Hauptpunkt: Schnitt der Hauptachse mit der Bildebene
\item Bildkoordinaten: 2D-Koordinaten \((u, v)\) eines Punktes im Bild. Einheit: Pixel
\item Kamerakoordinatensystem: 3D-Koordinaten \((x, y, z)\) eines Punktes relativ zur Kamera.
\item Weltkoordinatensystem: 3D-Basiskoordinatensystem der Weltkoordinaten
\end{itemize}

\textbf{Bildgenerierung}\\
\[\myVector{u \\ v} = \frac{f}{z}\myVector{x \\ y}\]

\textbf{Erweiterung zu unabhängigen Brennweiten}\\
\[\myVector{u \\ v} = \myVector{c_x \\ c_y} + \frac{1}{z}\myVector{f_x \cdot x \\ f_y \cdot y}\]

\textbf{Erweiterung mit Kalibriermatrix}\\
\[\myVector{u \cdot z\\ v \cdot z\\ z} = K \myVector{x \\ y \\ z}, \qquad K = \myMatrix{f_x & 0 & c_x\\ 0 & f_y & c_y \\ 0 & 0 & 1}\]

\subsection{Filteroperation}%
\label{bv:sub:filteroperation}
Operation auf einer Menge benachbarter Pixel, wird auf alle Pixel angewendet\\

\textbf{Linearer Filter}
\begin{itemize}
\item additiv --- \(f(x + y) = f(x) + f(y)\)
\item homogen --- \(f(\alpha x) = \alpha f(x)\)
\end{itemize}

\subsection{Segmentierung}%
\label{bv:sub:segmentierung}
Aufteilung eines Bildes in aussagekräftige Segmente\\
Jeder Pixel mindestens einem Segment zugeordnet

\subsubsection{Schwellwertfilter}%
\label{bv:ssub:schwellwertfilter}
Definiere Schwellwert um Grauwertbild in binäres Bild zu segmentieren\\
Alternativ Intervallschranken für Farbton

\subsection{Morphologische Operatoren}%
\label{bv:sub:morphologische-operatoren}
\begin{itemize}
\item Dilatation --- Vergrößere Pixel zu größeren Bereichen
\item Erosion --- Entfernt vereinzelte Pixel und schwach zusammenhängende Pixelgruppen
\end{itemize}

\textbf{Öffnen}: Erosion danach Dilatation, entferne dünne Linien, außenliegende Objekte\\
\textbf{Schließen}: Diltatation danach Erosion: Überbrückung kleiner Distanzen und Schließung von Löchern\\

\subsection{Filter}%
\label{bv:sub:filter}
\textbf{Prewitt}\\
Detektion von Kanten in X-Richtung und Y-Richtung. Aufgeteilt in 2 Richtungen
\[p_x = \myMatrix{-1 & 0 & 1\\-1 & 0 & 1\\ -1 & 0 & 1\\} \qquad p_y = \myMatrix{-1 & -1 & -1\\ 0 & 0 & 0\\ 1& 1 & 1\\}\]
Approximieren den Gradienten \(\frac{\delta g(x, y)}{\delta x}\) bzw. \(\frac{\delta g(x, y)}{\delta y}\)\\
Lässt sich kombinieren um Gradientenbetrag zu erhalten
\[M \approx \sqrt{P_x^2 + P_y^2}\]

\textbf{Sobel}\\
Ähnlich wie Prewitt, aber gewichtet Mitte stärker
\[s_x = \myMatrix{-1 & 0 & 1\\-2 & 0 & 2\\ -1 & 0 & 1\\} \qquad s_y = \myMatrix{-1 & -2 & -1\\ 0 & 0 & 0\\ 1& 2 & 1\\}\]

\textbf{Laplace}\\
Laplace-Operator \(\nabla^2 f= \frac{\delta^2 f}{\delta x^2}+ \frac{\delta^2 f}{\delta y^2}\) erkennt Kanten\\
\[\nabla^2 \approx \myMatrix{0 & 1 & 0 \\ 1 & -4 & 1 \\ 0 & 1 & 0}\]

\textbf{Laplacian of Gaussian (LoG)}\\
Anwenden von Gauß-Filter gefolgt von Laplace.

\subsection{Canny-Kantendetektor}%
\label{bv:sub:canny-kantendetektor}
Ziel: optimaler Kantendetektor
\begin{itemize}
\item Gute Detektion
\item Gute Lokalisierung
\item Minimale Antwort
\end{itemize}

Algorithmus:
\begin{enumerate}
\item Gauß-Filter \(\rightarrow\) Rauschunterdrückung
\item Berechnung der Intensitätsgradienten
\item Non-Maximum Suppression
\item Double Threshold
\item Kantenverfolgung mit Hystere
\end{enumerate}

Intensitätsgradienten mit Prewitt- oder Sobel-Filter

\subsection{Visual Servoing}%
\label{bv:sub:visual-servoing}
Visuelle Eingabedaten nutzen, um Bewegungen zu steuern, z.B. auf Grund von Modellfehlern oder anderen Ungenauigkeiten\\

\textbf{Kamera-in-Hand}\\
Kamera an Manipulator, Bewegungen des Manipulators beeinflussen Kamera\\

\textbf{Externe (feste) Kamera}\\
Beobachten der Bewegung (meist roter Ball)\\

\textbf{Bildmerkmal}\\
Ein Bildmerkmal \(s = (u,v)^T\) ist die Projektion eines 3D Punktes \(P (x, y, z)^T\) im Kamerabild\\
Geschwindigkeiten direkt aus aktuellen und gewünschten Bildmerkmalen\\

\subsection{Punktwolken}%
\label{bv:sub:punktwolken}
Diskrete Menge von 3D Punkten \(P = \{(X, C)\ |\ X \in \realnumbers^3,\ C \in [0 \ldots 255]^3 \subset \naturalnumbers^3_0\}\)
\begin{itemize}
\item \(X = (x, y, z)\) Ortsinformationen
\item \(C = (r, g, b)\) Farbinformationen
\end{itemize}
Repräsentiert als 2D Array oder Vektor\\

\textbf{Normalenschätzung}\\
Kovarianzmatrix der k-Nachbarschaft erstellen \(C = \frac{1}{k} \sum_1^k (p_i - \bar{p}) \cdot (p_i - \bar{p})^T\)
und berechne Eigenvektoren\\

\textbf{Registrierung}\\
Zusammenführen von Punktwolken aus verschiedenen Ansichten für das selbe Objekt
z.B. mit iterative Closest Point\\
Berechne Transformationen, sodass Punkte von B transformiert möglichst nahe an nächsten Punkten von A

\subsubsection{Iterative Closest Point (ICP)}%
\label{bv:ssub:iterative-closest-point}
Algorithmus für Registrierung zweier Mengen \(A,B\) mit a priori unbekannter Zuordnung\\
Vorgehen:
\begin{itemize}
\item Für jeden Punkt \(a_i\) aus \(A\) suche Punkt \(b_i\) aus \(B\), der \(a_i\) am nächsten liegt
\item Berechne Transformation \(T_k\) so dass \(D_k\) minimal wird, z.B. mit
  \(D_k = \sum_i || a_i - T_k \cdot b_i ||^2\)
\item \(D_k\) kombiniert Translation und Rotation
\item Wende Transformation \(T_k\) auf alle Punkte aus \(B\) an (Update).
\item Abbruch: Schwellwert oder Anzahl an Iterationen
\end{itemize}

\subsubsection{Random Sample Consensus (RANSAC)}%
\label{bv:ssub:random-sample-consensus}
Iterative Methode zur Schätzung von Modellparamtern aus Datenpunkten\\
Nicht-deterministisch!\\
Robust gegenüber Ausreißern\\
Vorgehen:
\begin{itemize}
\item Wähle zufällig die minimale Anzahl an Punkten aus, die nötig ist um die Modellparameter zu berechnen
\item Schätze ein Modell aus dem ausgewählten Datensatz
\item Bewertung der Modellschätzung (Bestimme inliers --- Punkte mit Abstand kleiner als Schwellwert)
\item Wiederhole bis das Modell mit den meistern Inliers gefunden
\end{itemize}

\subsection{Simultaneous localization and mapping (SLAM)}%
\label{bv:ssub:simultaneous-localization-and-mapping}
Bezeichnet das Problem eine Karte von einem Gebiet zu erstellen und gleichzeitig den Roboter zu lokalisieren.\\
Vorgehen:
\begin{enumerate}
\item Orientierungspunkte/Szenenfeatures auswählen
\item Vorhersage, wie viel sich der Roboter bewegt hat
\item Neue Orientierungspunkte/Szenenfeatures aufnehmen. Falls bekannte Features erkannt werden kann eine Zuordnung stattfinden
\item Interne Repräsentation aktualisieren (Messungenauigkeit beachten)
\end{enumerate}