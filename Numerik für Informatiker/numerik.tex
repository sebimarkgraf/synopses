\documentclass[10pt,a4paper]{article}
\author{Jannik Koch}
\title{Numerik für Informatiker}

\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage{mathrsfs}

\def\realnumbers{{\rm I\!R}}
\def\polynomials{{\rm I\!P}}

\newcommand{\rom}[1]{\uppercase\expandafter{\romannumeral #1\relax}}
\newcommand{\norm}[1]{\lVert#1\rVert}
\renewcommand{\arraystretch}{1.5}

\begin{document}
	\pagenumbering{Roman}
	{\let\newpage\relax\maketitle}
	\tableofcontents
	\newpage
	\pagenumbering{arabic}
	\setcounter{page}{1}

	\section{Grundlagen}
	Falls nicht anders genannt gilt für folgende Abschnitte: $A \in \realnumbers^{N \times N}, b \in \realnumbers^N$.
	
	\subsection{Vorwärts-/Rückwärtssubstitution}
	Zugrunde liegendes Problem ist die Lösung des linearen Gleichungssystems: $Ax = b$.\\
	\textbf{Voraussetzung:} A sei eine rechte obere oder linke untere Dreiecksmatrix.\\\\
	\textbf{Vorgehen:}
	\begin{enumerate}
		\item Lese die Lösung an der Stelle der Dreiecksmatrix ab, wo die Zeile nur einen Wert ungleich Null enthält
		\item Nutze diese Lösung in der nächsten Zeile um die nächste eindeutige Lösung zu ermitteln
		\item Wiederhole dies, bis alle Lösungen gefunden sind
		\item \textbf{Vorwärtssubstitution}:\\Matrix ist eine untere linke Dreiecksmatrix (Lösen von oben nach unten)
		\item \textbf{Rückwärtssubstitution}:\\Matrix ist eine obere rechte Dreiecksmatrix (Lösen von unten nach oben)
		\item Aufwand für Vor- bzw. Rückwärtssubstitution: ca. $\frac{N^2}{2}$
	\end{enumerate}

	\textbf{Bsp.:} Rückwärtssubstitution
	\begin{center}
		$\begin{bmatrix} 1 & 1\\0 & 3\\\end{bmatrix}x = \begin{bmatrix}2 \\ 3\end{bmatrix} \Rightarrow
		x_2 = 1 \Rightarrow x_1 + 1 = 2 \Rightarrow x_1 = 1 \Rightarrow x = \begin{bmatrix}1 \\ 1\end{bmatrix}$
	\end{center}
	
	\subsection{Gleitkommazahlen}
	\textbf{Darstellung}:
	\begin{itemize}
		\item Darstellung einer Gleitkommazahl z: $z = a * d^e$
		\item $d$: Basis, im Zweiersystem eine Zweierpotenz (2, 4, 8 etc.)
		\item $e$: Exponent, eine ganze Zahl zwischen $e_{min}$ und $e_{max}$
		\item $a$: Die Mantisse, entweder 0 oder eine Zahl mit $d^{-1} \leq |a| < 1$ der Form $a = v \sum_{i = 1}^{l} a_id^{-i}$ mit dem Vorzeichenbit v und der Mantissenlänge l
		\item Relative Maschinengenauigkeit: $eps = \frac{d^{(1-l)}}{2}$
		\item Rundungsfunktion $rd(x)$ rundet die Nachkommastellen auf ein maschinell darstellbares Format
	\end{itemize}
	\newpage
	\textbf{Operationen}:
	\begin{itemize}
		\item Standard-Operationen verfügbar, Rundung nach Ausführung $\Rightarrow$ Fehlerquelle!
		\item Aufgrund Rundung sind Operationen nicht assoziativ
		\item \textbf{Auslöschung}: Verlust der Genauigkeit bei der Subtraktion fast gleich großer Gleitkommazahlen
		\begin{itemize}
			\item Bsp.: Ergebnis zweier Operationen ist bis auf Rundungsfehler gleich, Zahlen werden subtrahiert, höherwertige Stellen werden 0 und die übrige Zahl der verfälschten Stellen steigt unverhältnismäßig (enormer relativer Fehler)
		\end{itemize}
		\item Es gilt: $1 + |y| = 1,\ falls\ |y| < eps$
	\end{itemize}
	
	
	\subsection{Matrixnormen}
	\begin{enumerate}
		\item{\makebox[13cm]{\textbf{Spaltensummennorm}: Summiere Spalten, wähle Maximalwert\hfill} $\norm{A}_1$}
		\item{\makebox[13cm]{\textbf{Spektralnorm}: Wurzel des größten Eigenwerts von $A^TA$\hfill} $\norm{A}_2$}
		\item{\makebox[13cm]{\textbf{Zeilensummennorm}: Summiere Zeilen, wähle Maximalwert\hfill} $\norm{A}_\infty$}
	\end{enumerate}
	
	\subsection{Konditionen}
	\textbf{Konditionszahl}:
	Sei $f: \realnumbers^N \rightarrow \realnumbers^K$ eine differenzierbare Funktion und $x \in \realnumbers^N$
	\begin{itemize}
		\item Maß für den Einfluss der Störungen von A und b auf x (wie sensibel ist das LGS?)
		\item Kondition einer Matrix: $1 \leq cond(A) := \norm{A}\norm{A^{-1}}$, wobei $cond(A) = cond(\alpha A), \alpha\in\realnumbers\setminus\{O\}$
		\item Absolute Konditionszahl: $\kappa^{kn}_{abs}(x) = |\frac{\delta}{\delta x_n}f_k(x)|$
		\item Relative Konditionszahl: $\kappa^{kn}_{rel}(x) = |\frac{\delta}{\delta x_n}f_k(x)| \frac{|x_n|}{|f_k(x)|}$ falls $f_k(x) \neq 0$
	\end{itemize}
	\newpage
	\section{Zerlegungen}
	Falls nicht anders genannt gilt für folgende Abschnitte: $A, R, L, Q \in \realnumbers^{N \times N}, b \in \realnumbers^N$.

	\subsection{LR-Zerlegung}
	Ziel: Zerlegung von A in eine \textbf{rechte obere Dreiecksmatrix R} und eine \textbf{linke untere Dreiecksmatrix L}, sodass gilt: $Ax = LRx = b$\\\\
	\textbf{Berechnen der LR-Zerlegung:}
	\begin{enumerate}
		\item Schreibe Matrix als Produkt $I_N * A$ mit der Einheitsmatrix $I_N$
		\item Forme schrittweise die rechte Matrix zu R um und notiere die Änderungen in der linken Matrix folgendermaßen:
		\begin{enumerate}
			\item Jede Operation wird als $Zeile\ A - Faktor * Zeile\ B$ notiert, auch\\
			Additionen (z.B als \rom{2}$ - (-2)$\rom{1}); Zeilen vertauschen ist nicht gestattet!
			\item Notiere den Vorfaktor an der Stelle, an der in R eine 0 entstanden ist
		\end{enumerate}
	\end{enumerate}
	\textbf{Bsp.:} $2\times2$ LR-Zerlegung
	\begin{center}
		$A = 
		\begin{bmatrix}1 & 2 \\ 3 & 4\end{bmatrix} =
		\begin{bmatrix}1 & 0 \\ 0 & 1\end{bmatrix} * \begin{bmatrix}1 & 2 \\ 3 & 4\end{bmatrix} \stackrel{II - 3I}{=}
		\begin{bmatrix}1 & 0 \\ 3 & 1\end{bmatrix} * \begin{bmatrix}1 & 2 \\ 0 & -2\end{bmatrix} = LR
		$	
	\end{center}
	\textbf{Berechnung mit Pivot-Suche}:\\
	\textbf{Idee:} A lässt sich durch Zeilenvertauschungen immer in eine Form bringen, sodass eine LR-Zerlegung sicher existiert (falls A regulär). Hiermit lässt sich auch die Konditionierung der Zerlegung verbessern.\\\\
	\textbf{Vorgehen}:
	\begin{enumerate}
		\item Wähle eine Permutationsmatrix P und zerlege PA, sodass gilt: $PA = LR$
		\item Löse $LRx = Pbx$
	\end{enumerate}
	\textbf{Permutationsmatrix für bessere Konditionierung durch Spaltenpivotsuche}:
	\begin{enumerate}
		\item Iteriere über die n Zeilen der Matrix A
		\item Bestimmte k, sodass $|A[k, n]| \geq |A[j, n]|$ für $j = n, ..., N$, d.h. suche in der aktuellen Spalte nach einem Eintrag unterhalb des aktuellen Eintrags, der betragsmäßig größer oder gleich ist
		\item Vertausche die Zeilen n und k, falls $k \neq n¸$
	\end{enumerate}
	\textbf{Performantes Lösen einer fertigen LR-Zerlegung:}
	\begin{enumerate}
		\item Substituiere $Rx$ mit $y\in\realnumbers^N$ und löse $Ly = b$ per Vorwärtssubstitution
		\item Löse $Rx = y$ per Rückwärtssubstitution
	\end{enumerate}
	\subsection{Cholesky-Zerlegung}
	Ziel: Zerlegung von A in eine \textbf{reguläre linke untere Dreiecksmatrix L}, wobei \textbf{A symmetrisch und positiv definit sein muss}, sodass gilt: $A = LL^T$\\\\
	\textbf{Berechnen der Cholesky-Zerlegung:}
	\begin{itemize}
		\item Alle Einträge über der Diagonalen sind 0, für alle anderen Einträge befolge dies zeilenweise:
		\begin{enumerate}
			\item Berechne die Summe $s_{ij} = a_{ij} - \sum_{k = 1}^{j - 1} l_{ik}l_{jk}$
			\item Für einen Diagonaleintrag gilt: $l_{ii} = \sqrt{s_{ii}}$ 
			\item Für einen Eintrag unter der Diagonalen gilt: $l_{ij} = \frac{s_{ij}}{l_{jj}}$
		\end{enumerate}
	\end{itemize}
	\textbf{Bsp.:} 3x3 Cholesky-Zerlegung
	\begin{center}
		$A = \begin{bmatrix}4 & 2 & 2\\2 & 17 & 5\\2 & 5 & 11\end{bmatrix}$\\\vspace*{0.5cm}
		$L = \begin{bmatrix}l_{11} & 0 & 0\\l_{21} & l_{22} & 0\\l_{31} & l_{32} & l_{33}\end{bmatrix}
		= \begin{bmatrix}
		  \sqrt{4 - 0} & 0 & 0\\
		  \frac{2 - 0}{2} & \sqrt{17 - 1 * 1} & 0\\
		  \frac{2 - 0}{2} & \frac{5 - 1 * 1}{4} & \sqrt{11 - (1 * 1 + 1 * 1)}
 		\end{bmatrix}
 		= \begin{bmatrix}
 			2 & 0 & 0\\
 			1 & 4 & 0\\
 			1 & 1 & 3
 		\end{bmatrix}$
	\end{center}
		
	\subsection{QR-Zerlegung}
	Ziel: Zerlegung von A in eine \textbf{rechte obere Dreiecksmatrix R} und eine \textbf{orthogonale Matrix Q}, sodass gilt: $A = QR$. Dies ist nützlich, wenn A nicht quadratisch ist, da die LR-Zerlegung dann nicht funktioniert.\\\\
	\textbf{Berechnen der QR-Zerlegung}:
	\begin{enumerate}
		\item Berechne $\alpha = sgn(a_{11})\norm{a_1}$ und damit $v_1 = a_1 + \alpha e_1$ und damit $Q_1 = I - \frac{2vv^T}{v^Tv}$ (Householder-Transformation)
		\item Berechne $Q_1A$. Das Ergebnis sollte die Elemente unter der ersten Spalte zu 0 reduziert haben. Wähle von diesem Ergebnis eine Untermatrix (ohne erste Zeile und erste Spalte) und wiederhole das Verfahren mit dieser und erhalte $Q_2^*$.
		\item Bette $Q_2^*$ in eine Einheitsmatrix mit denselben Dimensionen wie A ein und erhalte $Q_2$.
		\item Wiederhole 2. und 3. bis $Q_n * Q_{n - 1} * ... Q_1A = R$ Dreiecksgestalt hat.
		\item Multipliziere von links $Q_1^T * Q_2^T * ... Q_n^T = Q$ an beide Seiten.
	\end{enumerate}
	\newpage
	\textbf{Bsp.:}
	\begin{center}
		$A = \begin{bmatrix}1 & 1 & 2\\2 & -3 & 0 \\2 & 4 & -4\end{bmatrix}$\\\vspace*{0.5cm}
		$\Rightarrow \alpha_1 = 1 * \sqrt{1^2 + 2^2 + 2^2} = 3 \Rightarrow v_1 = \begin{bmatrix} 1 \\ 2 \\ 2\end{bmatrix} + 3 * \begin{bmatrix}1 \\ 0 \\ 0\end{bmatrix} = \begin{bmatrix} 4 \\ 2 \\ 2\end{bmatrix}$\\
		$\Rightarrow Q_1 = \begin{bmatrix}1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1\end{bmatrix} - \frac{2}{24} \begin{bmatrix}16 & 8 & 8 \\ 8 & 4 & 4\\ 8 & 4 & 4\end{bmatrix} = \frac{1}{3} \begin{bmatrix}-1 & -2 & -2 \\ -2 & 2 & -1 \\ -2 & -1 & 2\end{bmatrix}
		\Rightarrow Q_1A = \begin{bmatrix}-3 & -1 & 2 \\ 0 & -4 & 0 \\ 0 & 3 & -4\end{bmatrix}$\\\vspace*{0.5cm}
		Wdh. mit $\begin{bmatrix}-4 & 0 \\ 3 & -4\end{bmatrix}$\\
		$\Rightarrow Q_2^* = \frac{1}{5}\begin{bmatrix}-4 & 3 \\ 3 & 4\end{bmatrix} \Rightarrow Q_2 = \frac{1}{5}\begin{bmatrix}5 & 0 & 0\\0 & -4 & 3\\0 & 3 & 4\end{bmatrix} \Rightarrow Q_2Q_1A = \begin{bmatrix}-3 & -1 & 2 \\ 0 & 5 & -\frac{12}{5} \\ 0 & 0 & -\frac{16}{5}\end{bmatrix} = R$\\\vspace*{0.5cm}
		$Q_1^TQ_2^TQ_2Q_1A = Q_1^TQ_2^TR \Leftrightarrow A = Q_1^TQ_2^TR$\\
		$Q := Q_1^TQ_2^T \Rightarrow A = QR$
	\end{center}
	\textbf{Performantes Lösen einer fertigen QR-Zerlegung}:
	\begin{enumerate}
		\item A sei überbestimmt (keine LR-Zerlegung möglich) und $Ax = QRx = b$
		\item Multipliziere $A^T$ auf beiden Seiten: $A^TAx = (QR)^TQRx = R^TQ^TQRx = R^TRx = b$
		\item Löse $R^TRx = b$ analog zum LR-Verfahren per Vorwärts- und Rückwärtssubstitution
	\end{enumerate}
	\subsection{Aufwand}
	\begin{itemize}
		\item QR-Zerlegung mit N = M:\hfill$\frac{4}{3}N^3$ Operationen
		\item LR-Zerlegung:\hfill$\frac{2}{3}N^3$ Operationen
		\item Cholesky-Zerlegung:\hfill$\frac{1}{3}N^3$ Operationen
	\end{itemize}
	\newpage
	\section{Lineare Ausgleichsrechnung}
	\textbf{Problem}: Lineare Gleichungssysteme oft nicht oder nicht eindeutig lösbar.\\
	\textbf{Lösung}: Versuche die bestmögliche Lösung zu finden, sodass gilt: für $x \in \realnumbers^N$ ist $|Ax - b|_2$ minimal
	\begin{center}
		Hierbei gilt: $x \in \realnumbers^N$ minimiert $|Ax - b|_2 \Leftrightarrow$ $x \in \realnumbers^N$ löst die Normalengleichung $A^TAx = A^Tb$
	\end{center}
	\subsection{Per QR-Zerlegung}
	Voraussetzung: $A^TA$ ist invertierbar und gut konditioniert\\
	\textbf{Vorgehen}:
	\begin{enumerate}
		\item Berechne QR-Zerlegung: $A = QR$, dann ist $A^TA = R^TR$ (s. Kapitel zu QR-Zerlegung)
		\item Löse $Rx = Q^Tb$
	\end{enumerate}
	
	\subsection{Per Singulärwertzerlegung}
	Alternative zum QR-Ansatz falls gilt: $A^TA$ ist singulär (besitzt keine Inverse) oder schlecht konditioniert. Sei für diesen Fall $A \in \realnumbers^{K\times N}$. Zerlege A folgendermaßen $A = V\Sigma U^T$. Sei $R = rang(A)$. Hierbei gilt:
	\begin{itemize}
		\item $V \in \realnumbers^{K\times R}$, wobei $V^TV = I_R$
		\item $U \in \realnumbers^{N\times R}$
		\item $\Sigma = diag(\sigma_1, ..., \sigma_R) \in \realnumbers^{R\times R}$ mit den Singulärwerten $\sigma_1, ..., \sigma_R > 0$
	\end{itemize}
	Die Bestimmung der einzelnen Matrizen ist nicht klausurrelevant.
	
	\subsection{(Tikhonov)-Regularisierung}
	\textbf{Problem}: Eine Aufgabe ist potenziell schlecht konditioniert (sorgt für extreme Datenfehler) oder nicht sachgemäß gestellt (und damit nicht eindeutig lösbar oder nicht stetig abhängig von den Daten).\\
	\textbf{Lösung}: Regularisiere die Aufgabe, sodass sie gut konditioniert bzw. sachgemäß gestellt ist. Hierzu wird die sog. Tikhonov-Regularisierung ($F_\alpha(x)$) minimiert.
	
	\section{Eigenwertberechnung}
	\textbf{Ziel:} Berechnung von Eigenwerten und Eigenvektoren (z.B für Zwecke der Informatik wie das Lösen des Problems \glqq Welche Seite hat einen Link auf welche Seite?\grqq oder der Technik für Wellengleichungen).\\
	\textbf{Verfahren}: Vereinfachen der Matrix (z.B zu Hessenberg-Matrix über Householder-Transformationen) oder iterative Verfahren (v.a. QR-Iteration, benötigt $O(N^2)$ Operationen)

	\section{Iterationsverfahren für lineare Gleichungssysteme}
	\textbf{Ziel}: Iteratives Lösen eines linearen Gleichungssystems.\\\\
	\textbf{Anwendung}: Graphentheorie z.B zur Bisektion eines Graphen, Berechnung der Auslenkung einer Membran unter einer bestimmten Last in der Technik.
	\subsection{Jacobi-Verfahren (Gesamtschrittverfahren)}
	\textbf{Idee}: Approximiere die Lösung $x \in \realnumbers^N$. Wähle x dazu beliebig und setze einen Schwellenwert $\epsilon > 0$ sowie $k = 0$. Solange $|Ax - b|_2 > \epsilon$, berechne
	\begin{center}
		$x^{k+1}_m = (b_m - \sum_{n \neq m}^{} A[m, n]x_n^k) / A[m, m]$ für $m = 1, ..., N$
	\end{center}
	und erhöhe k um 1. Erweitert man diesen Algorithmus mit der Idee, dass die $x_n$ bei der Berechnung von $x_m$ schon bekannt sind, falls $n < m$, so erhält man das Einzelschrittverfahren.
	\subsection{Gauß-Seidel-Verfahren (Einzelschrittverfahren)}
	Vergleiche Jacobi-Verfahren und ändere die Formel für die nächstbeste Approximation von x zu:
	\begin{center}
		$x^{k+1}_m = (b_m - \sum_{n = 1}^{m - 1}A[m, n]x^{k+1}_n - \sum_{k = m + 1}^{N}A[m, n]x_n^k) / A[m, m]$ für $m = 1, ..., N$
	\end{center}
	
	\subsection{Iterationsmatrizen}
	\textbf{Idee}: Stelle Iterationsverfahren in Matrizenschreibweise dar. Diese Iterationsmatrix ergibt sich aus der eigentlichen Funktionsgleichung und kann als gegeben betrachtet werden.\\\\
	\textbf{Vorkonditionierung}: Um die Kondition der Matrix A zu verbessern, wird ein Vorkonditionierer $B \in \realnumbers^{N\times N}$ gewählt. Hierzu zerteilen wir A in eine strikte untere linke Dreiecksmatrix L, eine strikte obere rechte Dreiecksmatrix R und eine Diagonalmatrix D mit $A = L + D + R$. Damit ist der Vorkonditionierer \textbf{für das Jacobi-Verfahren} $B = D^{-1}$ und für das \textbf{Gauß-Seidel-Verfahren} $B = (L + D)^{-1}$. Für die vorkonditionierte Aufgabe gilt damit:
	\begin{center}
		$Ax = b \Leftrightarrow BAx = Bb$
	\end{center}
	\textbf{Konvergenz}: Das Iterationsverfahren konvergiert genau dann für jeden Startvektor $x_0$, falls der Spektralradius (betragsmäßig größter Eigenwert) der Iterationsmatrix kleiner als 1 ist.
	\newpage
	\section{Iterationsverfahren für nichtlineare Gleichungssysteme}
	\subsection{Newton-Verfahren}
	\textbf{Idee}: Zugrunde liegende Gleichung ist nichtlinear (z.B Polynom von mindestens Grad zwei, Bruchgleichungen, Wurzelgleichungen, Exponentialgleichungen etc.). Nähere hierfür die Lösung durch die Newton-Iteration an. Hierbei bestimmt man die Tangente des aktuellen Punkts, wählt die Nullstelle der Tangente und fährt von dieser an fort. Für einen Vektor $x_k$ folgt für eine Funktion $F(x)$ die nächste Näherung durch die Newton-Iteration $x_{k + 1} = x_k - \frac{F(x_k)}{F'(x_k)}$.\\\\
	\textbf{Das Newton-Verfahren konvergiert nur für einen guten Startwert!}\\\\
	\textbf{Lösungssuche über Newton-Verfahren}:\\
	Bsp.: Finden der n-ten Wurzel
	\begin{enumerate}
		\item Gesucht: $x = \sqrt[n]{2}$\\formuliere als Nullstellenproblem: $x^n = 2 \Leftrightarrow x^n - 2 = 0 \Rightarrow F(x) = x^n - 2$ und $F'(x) = nx^{n - 1}$
		\item Iteriere für z.B $n = 5$ folgendermaßen:
		\begin{enumerate}
			\item $x_1 = 2$
			\item $x_2 = 2 - \frac{2^5 - 2}{5 * 2^4} = 2 - \frac{30}{80} = \frac{13}{8}$
			\item $x_3 = \frac{13}{8} - \frac{(\frac{13}{8})^5 - 2}{5 * (\frac{13}{8})^4} \approx 1.357364938$
			\item etc. (Lösung des Taschenrechners: $x \approx 1.148698355$)
		\end{enumerate}
	\end{enumerate}
	\textbf{Lösen einer Minimierungsaufgabe}:                                                                                        \\
	Zur Minimierung einer differenzierbaren Funktion $f: \realnumbers^N \rightarrow \realnumbers$ suche $x^* \in \realnumbers^N$ mit \\$f(x^*) \leq f(x) \forall x \in \realnumbers^N$. Dies lässt sich erreichen, indem man das Nullstellenproblem\\$F(x) = grad\ f(x) = 0$ berechnet. Die damit folgende Newton-Iterationsvorschrift lautet:
	\begin{center}
		$x_{k + 1} = x_k - F''(x_k)^{-1} grad\ f(x_k)$
        \end{center}
        \textbf{Allgemeine Gleichung für mehrdimensionale Probleme}
        \begin{enumerate}
        	\item Wähle Startwert $x_0$ und $\epsilon$
        	\item Falls $|F(x^k)| < \epsilon$: STOP
        	\item Berechne Newton Korrektur $d^k: F^{\prime}(x^k)d^k = -F(x^k)$
        	\item Setze: $x^{k+1} = x^{k} + d^{k}$
        \end{enumerate}

        \section{Polynom-Interpolation}
	\textbf{Problem}: Nur eine endliche Punktmenge einer Funktion ist gegeben. Zur Erschließung der Kurve kann nur zwischen diesen Punkten interpoliert werden. Dies ermöglicht z.B Datenkompression, aber verursacht ebenfalls Interpolationsfehler. Hierbei benötigt \textbf{eine Menge von N Punkten ein Polynom von Grad N-1!}\\\\
	\textbf{Interpolationsaufgabe nach Lagrange}:\\
	Zu Stützstellen $\xi_0 < \xi_1 < ... < \xi_N$ und Funktionswerten $f_0, ..., f_N \in \realnumbers$ bestimme ein Polynom P mit $P(\xi_i) = f_i$ für $i = 0, ..., N$
	
	\subsection{Neville-Schema}
	Über das Neville-Schema kann der Funktionswert an einer nicht gegebenen Stelle rekursiv berechnet werden. Man berechnet hierzu jeweils das eindeutig bestimmte Interpolationspolynom $p(f|\xi_i ... \xi_j)$ k-ten Grades zu den k + 1 Stützpunkten.\\\\ Die Funktionswerte der Stützpunkte sind bereits gegeben, weswegen für alle $\xi_i$ der Wert $p(f|\xi_i)$ durch $f_i$ gegeben ist. Die Rekursionsformel der weiteren Einträge lautet:
	\begin{center}
		$p(f|x_i,...,x_j)(x) = \frac{(x - x_i) p(f|x_{i + 1},...,x_j)(x) - (x - x_j)p(f|x_i,...,x_{j-1})(x)}{x_j - x_i}$
	\end{center}
	Damit ist ein rekursiver Aufbau folgendermaßen beispielhaft möglich (gesucht ist der Funktionswert an Stelle $x = 4$):\\
	\begin{center}
		\begin{tabular}{c | c l c c}
			$\xi_i$ & $f(\xi_i)$ & & &\\
			\hline
			1 & 2 & $\frac{4 - 0}{1 - 0} * 2 + \frac{1 - 4}{1 - 0} * 1 = 5$ & &\\
			2 & 0 & $\frac{4 - 1}{2 - 1} * 0 + \frac{2 - 4}{2 - 1} * 2 = -4$ & -13 &\\
			3 & 1 & $\frac{4 - 2}{3 - 2} * 1 + \frac{3 - 4}{3 - 2} * 0 = 2$ & 5 & 11 = $P_3(4)$
		\end{tabular}
	\end{center}
	Das Neville-Schema liefert \textbf{nicht das eigentliche Interpolationspolynom}, sondern den \textbf{Funktionswert an einer bestimmten Stelle}! Um das eigentliche Polynom zu erhalten müssen Alternativverfahren wie das Newtonsche verwendet werden. Dieses ist aufwendiger, lohnt sich jedoch, wenn viele Stellen ausgewertet werden müssen. Das Neville-Schema ist gut für wenige Suchen geeignet. Für einen weiteren Stützpunkt wird hier \textbf{eine zusätzliche Zeile berechnet, die alten Ergebnisse bleiben valide!}
	\newpage
	\section{Splines}
	\textbf{Idee}: Interpoliere nicht mit einem passenden Polynom sondern setze die Lösung mit mehreren Polynomen stückweise zusammen. Diese Funktion wird als Spline bezeichnet (nicht ein einzelnes Stück davon!). \textbf{Splines sind in der Regel selbst keine Polynome!}. Eine einfache Lösung sind \textbf{lineare Splines}, bei denen zwischen den Stützpunkten linear verbunden wird - diese sind jedoch nicht glatt und an den Stützpunkten nicht differenzierbar.
	
	\subsection{Kubische Splines}
	\textbf{Idee}: Nutze kubische Polynome, damit der Spline glatt und auch an den Stützpunkten zweifach stetig differenzierbar ist.\\\\
	\textbf{Grundlegende Definitionen}:\\
	\begin{itemize}
		\item Zu einer Zerlegung $\Xi = \{a = \xi_0 < \xi_1 < ... < \xi_N = b\}$ des Intervalls $[a, b]$ definiere den Raum kubischer Splines:
		\begin{center}
			$\mathscr{S}_3(\Xi) = \{S \in C^2[a, b]: S_n = S|_{[\xi_{n-1}, \xi_n]} \in \polynomials_3, n = 1, ..., N\}$
		\end{center}
		\item Dabei heißt für $f \in C[a, b]$ der Spline $S \in \mathscr{S}_3(\Xi)$ interpolierender kubischer Spline zu f, wenn gilt:
		\begin{center}
			$S(\xi_n) = f(\xi_n)$, $n = 0, ..., N$
		\end{center}
	\end{itemize}
	\textbf{Randbedigungen zur eindeutigen Bestimmung:}\\
	Mit jeweils einer dieser Randbedingungen ist die Spline-Interpolation $S \in \mathscr{S}_3(\Xi)$ zu f eindeutig lösbar:
	\begin{itemize}
		\item Natürliche Randbedingung:\hfill$S''(a) = S''(b) = 0$
		\item Hermite-Randbedingungen zu $f \in C^1[a, b]$:\hfill$S'(a) = f'(a)$ und $S'(b) = f'(b)$
		\item Periodische Randbedingungen:\hfill$S'(a) = S'(b)$ und $S''(a) = S''(b)$
	\end{itemize}
	Weiter seien die \textbf{Momente} $\mu_n = S''(\xi_n)$ eines Interpolationssplines $S \in \mathscr{S}_3(\Xi)$ zu f definiert als $\mu_n = S''(\xi_n)$. Die Momente ergeben sich durch das Lösen von Gleichungssystemen passend zu den Randbedingungen (vgl. Skript, nicht klausurrelevant).\\\\
	\textbf{Berechnung eines Splines durch 3 Punkte}: TODO\\
	% TODO
	\newpage
	\section{Trigonometrische Interpolation und Fast-Fourier-Transformation (FFT)}
	\textbf{Anwendung}: Datenkompression (weniger Werte speichern, bei Bedarf interpolieren), Schwingungsanalyse\\
	\textbf{Aufwand}: O(N log N)
	% TODO?
	
	\section{Numerische Integration}
	\textbf{Problem}: Eine Stammfunktion für die reguläre Integration kann nicht immer gefunden werden, deshalb wird auf numerische Verfahren zurückgefallen.\\\\
	\textbf{Idee}: Approximiere den Wert des Integrals mit dem Wert Q(f) einer Quadraturformel Q. Diese besteht aus einer gewichteten Summe von Funktionswerten (Stützpunkten aus $\Xi$, wobei $\Xi \subset [a, b]$):
	\begin{center}
		$Q_\Xi(f) = \sum_{\xi \in \Xi}^{}\omega_\xi f(\xi)$
	\end{center}
	\textbf{Berechnung der Gewichte}:\\
	Für die Quadraturgewichte gilt:
	\begin{center}
		$\omega_\xi = \int_{a}^{b}L_\xi(t)dt$ mit $L_\xi(t) = \prod_{\eta \in \Xi \setminus \{\xi\}}^{} \frac{t - \eta}{\xi - \eta} \in \polynomials_N$\\
		Für Polynome vom Grad N - 1: $Q_\Xi(P) = \int_{a}^{b}P(t)dt, P \in \polynomials_{N - 1}$
	\end{center}
	\textbf{Messung der Genauigkeit}: TODO\\
	% TODO
        
        \subsection{Wichtige Quadraturformeln}
        Trapezregel: $\int_{a}^{b} f(x) = \frac{b - a}{2} (f(a) + f(b))$ \\
        Simpsonregel: $\int_{a}^{b} f(x) = \frac{b - a}{6} (f(a) + 4f(\frac{a-b}{2}) + f(b))$ \\
        Newton'sche $\frac{3}{8}$-Regel: $w_0 = w_3 \frac{b - a}{8}, w_1 = w_2 = \frac{3(b - a)}{8}$ \\
        Milne-Regel: $w_0 = w_4 = \frac{7(b - a)}{90}, w_1 = w_3 = \frac{32(b - a)}{90}, w_2 = \frac{12(b - a)}{90}$ \\
	
	\subsection{Summierte Trapezregel}
	\textbf{Ansatz (Summierte Quadraturformel)}: Zerlege das Intervall $[a, b]$ in gleich große Stücke und wende die Quadraturformel auf jedem Teilinterval an.\\\\
	\textbf{Summierte Trapezregel}: Zerlege Flächen unter einer Kurve im gegebenen Intervall in Trapeze. Im Vergleich zu FFT: FFT zerlegt ein Signal in verschiedene Frequenzanteile.
	\newpage
	\section{Integrationsverfahren für gewöhnliche Differentialgleichungen}
	\subsection{Runge-Kutta-Verfahren}
	\textbf{Ziel}: Numerisches Lösen von Anfangswertproblemen. Definition eines Anfangswertproblems:
	\begin{center} 
		$y'(t) = f(t, y(t)), y(t_0) = y_0, y: \realnumbers \rightarrow \realnumbers^d$
	\end{center}
	\textbf{Beispiele}:\\
	Die verschiedenen Runge-Kutta-Verfahren unterscheiden sich in erster Linie in der Konvergenzordnung R. Mit höherer Konvergenzordnung wächst die Zahl zu lösender Gleichungen schnell an, die Ergebnisse werden dafür jedoch genauer.
	\begin{itemize}
		\item Explizites Euler-Verfahren (R = 1)
		\item Verfahren von Heun (R = 2)
		\item Klassisches Runge-Kutta-Verfahren (R = 4)
	\end{itemize}
\end{document}